# -*- coding: utf-8 -*-
"""XAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qyAdeRukVaEXXId2xD1ttaFLxKAzSxLG
"""

# ===============================
# 1. Setup
# ===============================
!pip install kaggle torch torchvision scikit-learn opencv-python tqdm matplotlib

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import numpy as np
import matplotlib.pyplot as plt
import cv2
from PIL import Image
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

from google.colab import files
files.upload()  # upload kaggle.json

# ===============================
# 2. Download Dataset (Kaggle)
# ===============================

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content --unzip

# ===============================
# 3. Data Preprocessing
# ===============================
IMG_SIZE = 224

train_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.485,0.485],[0.229,0.229,0.229])
])

test_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.485,0.485],[0.229,0.229,0.229])
])

data_dir = "/content/chest_xray"
train_ds = datasets.ImageFolder(os.path.join(data_dir, "train"), transform=train_tf)
val_ds   = datasets.ImageFolder(os.path.join(data_dir, "val"), transform=test_tf)
test_ds  = datasets.ImageFolder(os.path.join(data_dir, "test"), transform=test_tf)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False)
test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False)

class_names = train_ds.classes
print("Classes:", class_names)

# ===============================
# 4. Model (DenseNet121)
# ===============================
model = models.densenet121(pretrained=True)
num_ftrs = model.classifier.in_features
model.classifier = nn.Linear(num_ftrs, 2)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# ===============================
# 5. Training Loop
# ===============================
def train_model(model, train_loader, val_loader, epochs=5):
    best_auc = 0
    for epoch in range(epochs):
        model.train()
        train_loss, preds, labels = 0, [], []

        for imgs, lbls in tqdm(train_loader):
            imgs, lbls = imgs.to(device), lbls.to(device)
            optimizer.zero_grad()
            out = model(imgs)
            loss = criterion(out, lbls)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
            preds += out.softmax(1)[:,1].detach().cpu().numpy().tolist()
            labels += lbls.cpu().numpy().tolist()

        train_auc = roc_auc_score(labels, preds)

        # Validation   (this is for new images which we upload) //till now training is done ,now its time to testing
        model.eval()
        val_preds, val_labels = [], []
        with torch.no_grad():
            for imgs, lbls in val_loader:
                imgs = imgs.to(device)
                out = model(imgs)
                val_preds += out.softmax(1)[:,1].cpu().numpy().tolist()
                val_labels += lbls.numpy().tolist()
        val_auc = roc_auc_score(val_labels, val_preds)

        print(f"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss/len(train_loader):.4f} | Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}")

        if val_auc > best_auc:
            best_auc = val_auc
            torch.save(model.state_dict(), "best_model.pth")
    print("Training Complete. Best Val AUC:", best_auc)

train_model(model, train_loader, val_loader, epochs=5)

# ===============================
# 6. Grad-CAM Implementation
# ===============================
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.gradients = None
        self.activations = None
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output.detach()

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0].detach()

    def __call__(self, input_tensor, class_idx=None):
        output = self.model(input_tensor)
        if class_idx is None:
            class_idx = output.argmax(dim=1).item()
        score = output[0, class_idx]
        self.model.zero_grad()
        score.backward(retain_graph=True)

        grads = self.gradients[0]
        acts  = self.activations[0]
        weights = grads.mean(dim=(1,2))
        cam = torch.zeros(acts.shape[1:], dtype=torch.float32).to(acts.device)
        for i, w in enumerate(weights):
            cam += w * acts[i]
        cam = F.relu(cam)
        cam = (cam - cam.min()) / (cam.max() - cam.min())
        cam = cam.cpu().numpy()
        cam = cv2.resize(cam, (input_tensor.size(-1), input_tensor.size(-2)))
        return cam, class_idx

# ===============================
# 7. Test on New Image
# ===============================
# Load best model
model.load_state_dict(torch.load("best_model.pth", map_location=device))
model.eval()

# Grad-CAM on last layer
target_layer = model.features.norm5
gradcam = GradCAM(model, target_layer)

# Upload new image
from google.colab import files
uploaded = files.upload()

img_path = list(uploaded.keys())[0]
img = Image.open(img_path).convert("RGB")
transform = test_tf
input_t = transform(img).unsqueeze(0).to(device)

# Prediction
out = model(input_t)
pred = torch.argmax(out, 1).item()
print("Prediction:", class_names[pred])

# Grad-CAM Heatmap
cam, cls = gradcam(input_t)
heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)
orig = np.array(img.resize((IMG_SIZE, IMG_SIZE)))
overlay = 0.5*orig + 0.5*heatmap

plt.figure(figsize=(12,4))
plt.subplot(1,3,1); plt.title("Original"); plt.imshow(orig); plt.axis('off')
plt.subplot(1,3,2); plt.title("Grad-CAM"); plt.imshow(heatmap); plt.axis('off')
plt.subplot(1,3,3); plt.title("Overlay"); plt.imshow(overlay.astype(np.uint8)); plt.axis('off')
plt.show()

